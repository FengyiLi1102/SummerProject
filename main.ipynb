{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries required\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def reduce_memory(df, verbose=True):\n",
    "    \"\"\"\n",
    "    :param: df - dataframe required to decrease the memory usage\n",
    "    :param: verbose - show logging output if 'Ture'\n",
    "\n",
    "    Goal: Reduce the memory usage by decreasing the type of the value if applicable\n",
    "\n",
    "    Return: original dataframe with lower memory usage\n",
    "    \"\"\"\n",
    "\n",
    "    numerics = ['int64', 'int16', 'int32', 'float64', 'float32', 'float16']\n",
    "    start_memory = df.memory_usage().sum() / 1024**2\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    end_memory = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_memory, 100 * (start_memory - end_memory) / start_memory))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def struc1_merge(df1, df2, index):\n",
    "    \"\"\"\n",
    "    :param: df1 - training data\n",
    "    :param: df2 - structure data after being added electronegativity, radius, bond_lengths, hybridization, surrounding atoms (bonds),\n",
    "            position info. (x, y, z)\n",
    "    :param: index - atom_index in the coupling\n",
    "\n",
    "    Goal: Merge original training dataframe with processed structure data to form a new dataframe for further training process\n",
    "\n",
    "    Return: Merged dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    struc1_train_merge = pd.merge(df1, df2, how='left',\n",
    "                                  left_on=['molecule_name', f'atom_index_{index}', f'atom_{index}', f'x_{index}', f'y_{index}', f'z_{index}'],\n",
    "                                  right_on=['molecule_name', 'atom_index', 'atom', 'x', 'y', 'z'])\n",
    "    \n",
    "    struc1_train_merge = struc1_train_merge.drop(['n_bonds'], axis=1)\n",
    "    \n",
    "    struc1_train_merge = struc1_train_merge.rename(columns={'EN': f'EN_{index}',\n",
    "                                                            'RD': f'RD_{index}',\n",
    "                                                            'bond_lengths': f'bond_lengths_{index}',\n",
    "                                                            'hybri': f'hybri_{index}',\n",
    "                                                            'bonds': f'bonds_{index}',\n",
    "                                                            'pi_bonds': f'pi_bonds_{index}'})\n",
    "    \n",
    "    return struc1_train_merge\n",
    "\n",
    "\n",
    "def n_bonds(structures):\n",
    "    \"\"\"\n",
    "    :param: structures - structure.csv from local data\n",
    "    \n",
    "    Goal: Calculate the number of bonds for each molecule.\n",
    "\n",
    "    Return: Structure dataframe with number of bonds (n_bonds) and lists consisting of indexes of connecting atoms (bonds)\n",
    "    \"\"\"\n",
    "\n",
    "    i_atom = structures['atom_index'].values\n",
    "    p = structures[['x', 'y', 'z']].values\n",
    "    p_compare = p\n",
    "    m = structures['molecule_name'].values\n",
    "    m_compare = m\n",
    "    r = structures['RD'].values\n",
    "    r_compare = r\n",
    "\n",
    "    source_row = np.arange(len(structures))\n",
    "    max_atoms = 28\n",
    "\n",
    "    bonds = np.zeros((len(structures)+1, max_atoms+1), dtype=np.int8)\n",
    "    bond_dists = np.zeros((len(structures)+1, max_atoms+1), dtype=np.float32)\n",
    "\n",
    "    print('Calculating bonds')\n",
    "\n",
    "    for i in tqdm(range(max_atoms-1)):\n",
    "        p_compare = np.roll(p_compare, -1, axis=0)\n",
    "        m_compare = np.roll(m_compare, -1, axis=0)\n",
    "        r_compare = np.roll(r_compare, -1, axis=0)\n",
    "\n",
    "        mask = np.where(m == m_compare, 1, 0) #Are we still comparing atoms in the same molecule?\n",
    "        dists = np.linalg.norm(p - p_compare, axis=1) * mask\n",
    "        r_bond = r + r_compare\n",
    "\n",
    "        bond = np.where(np.logical_and(dists > 0.0001, dists < r_bond), 1, 0)\n",
    "\n",
    "        source_row = source_row\n",
    "        target_row = source_row + i + 1 #Note: Will be out of bounds of bonds array for some values of i\n",
    "        target_row = np.where(np.logical_or(target_row > len(structures), mask==0), len(structures), target_row) #If invalid target, write to dummy row\n",
    "\n",
    "        source_atom = i_atom\n",
    "        target_atom = i_atom + i + 1 #Note: Will be out of bounds of bonds array for some values of i\n",
    "        target_atom = np.where(np.logical_or(target_atom > max_atoms, mask==0), max_atoms, target_atom) #If invalid target, write to dummy col\n",
    "\n",
    "        bonds[(source_row, target_atom)] = bond\n",
    "        bonds[(target_row, source_atom)] = bond\n",
    "        bond_dists[(source_row, target_atom)] = dists\n",
    "        bond_dists[(target_row, source_atom)] = dists\n",
    "\n",
    "    bonds = np.delete(bonds, axis=0, obj=-1) #Delete dummy row\n",
    "    bonds = np.delete(bonds, axis=1, obj=-1) #Delete dummy col\n",
    "    bond_dists = np.delete(bond_dists, axis=0, obj=-1) #Delete dummy row\n",
    "    bond_dists = np.delete(bond_dists, axis=1, obj=-1) #Delete dummy col\n",
    "\n",
    "    print('Counting and condensing bonds')\n",
    "\n",
    "    bonds_numeric = [[i for i,x in enumerate(row) if x] for row in tqdm(bonds)]\n",
    "    bond_lengths = [[dist for i,dist in enumerate(row) if i in bonds_numeric[j]] for j,row in enumerate(tqdm(bond_dists))]\n",
    "    n_bonds = [len(x) for x in bonds_numeric]\n",
    "\n",
    "    #bond_data = {'bond_' + str(i):col for i, col in enumerate(np.transpose(bonds))}\n",
    "    #bond_data.update({'bonds_numeric':bonds_numeric, 'n_bonds':n_bonds})\n",
    "\n",
    "    bond_data = {'bonds':bonds_numeric, 'n_bonds':n_bonds, 'bond_lengths':bond_lengths}\n",
    "    bond_df = pd.DataFrame(bond_data)\n",
    "    structures = structures.join(bond_df)\n",
    "    \n",
    "    return structures\n",
    "\n",
    "\n",
    "def struc_merge(df, struc, index):\n",
    "    \"\"\"\n",
    "    :param: df - The dataframe to be merged with structure data\n",
    "    :param: struc - structure data\n",
    "    :param: index - index of atom in the coupling\n",
    "\n",
    "    Goal: Merger two dataframe.\n",
    "\n",
    "    Return: a new dataframe after merged\n",
    "    \"\"\"\n",
    "\n",
    "    # Merge train and structures data based on the atom index\n",
    "    df_struc = pd.merge(df, struc, how='left', \n",
    "                        left_on=['molecule_name', f'atom_index_{index}'], \n",
    "                        right_on=['molecule_name', 'atom_index'])\n",
    "\n",
    "    # Drop the atom index column\n",
    "    df_struc = df_struc.drop('atom_index', axis=1)\n",
    "\n",
    "    # Rename the columns\n",
    "    df_struc = df_struc.rename(columns={'atom': f'atom_{index}',\n",
    "                                        'x': f'x_{index}',\n",
    "                                        'y': f'y_{index}',\n",
    "                                        'z': f'z_{index}'})\n",
    "\n",
    "    return df_struc\n",
    "\n",
    "\n",
    "def distance(df, structures):\n",
    "    \"\"\"\n",
    "    :param: df - Data that need to calculate distance\n",
    "\n",
    "    Goal: Calculate the distance between two spins\n",
    "\n",
    "    Return: DataFrame with distance added\n",
    "    \"\"\"\n",
    "\n",
    "    # Make a copy of  the data for avoiding changing the original data\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Merge data\n",
    "    df_copy = struc_merge(df_copy, structures, 0)\n",
    "    df_copy = struc_merge(df_copy, structures, 1)\n",
    "\n",
    "    %%time\n",
    "    # This block for calculating the distance between two spins\n",
    "    df_p_0 = df_copy[['x_0', 'y_0', 'z_0']].values\n",
    "    df_p_1 = df_copy[['x_1', 'y_1', 'z_1']].values\n",
    "\n",
    "    df_copy['distance'] = np.linalg.norm(df_p_0 - df_p_1, axis=1)\n",
    "\n",
    "    return df_copy\n",
    "\n",
    "\n",
    "def hybridization(structures):\n",
    "    \"\"\"\n",
    "    :param: structures - structures data\n",
    "\n",
    "    Goal: Calculate each hybridization in the structures data\n",
    "\n",
    "    Return: structure data with hybridization column added\n",
    "    \"\"\"\n",
    "    \n",
    "    # 'C' has different types of hybridizations with different number of bonds.\n",
    "    # '4' for four bonds\n",
    "    hybri_dict = {'C': {'4': 3, '3': 2, '2': 2, '1': 0},\n",
    "                  'N': {'4': 0, '3': 3, '2': 2, '1': 1},\n",
    "                  'O': {'2': 2, '1': 1},\n",
    "                  'H': {'1': 0},\n",
    "                  'F': {'1': 0}}\n",
    "                # 3 bonds- sp3, 2 - sp2, 1 - sp\n",
    "    \n",
    "    hybri = []\n",
    "\n",
    "    for i in tqdm(range(len(structures))):\n",
    "        hybri.append(hybri_dict[structures.loc[i, 'atom']][str(structures.loc[i, 'n_bonds'])])\n",
    "    \n",
    "    structures['hybri'] = hybri\n",
    "\n",
    "    return structures\n",
    "\n",
    "\n",
    "def pi_bonds(structures):\n",
    "    \"\"\"\n",
    "    :param: structures - structures data\n",
    "\n",
    "    Goal: Calculate the number of pi_bonds for each atom\n",
    "\n",
    "    Return: structures with pi_bonds column added\n",
    "    \"\"\"\n",
    "\n",
    "    # The number of atoms connecting to an atom is related with the number of pi bonds.\n",
    "    # Eg: In 'C', if there are 4 bonds around, then the number of pi bonds is 0.\n",
    "    pi_bond = {'C': {'4': 0, '2': 2, '3': 1},\n",
    "               'N': {'4': 0, '3': 0, '2': 1, '1': 2},\n",
    "               'O': {'1': 1, '2': 0},\n",
    "               'H': {'1': 0},\n",
    "               'F': {'1': 0}}\n",
    "\n",
    "    pi_bond_ = []\n",
    "\n",
    "    for i in tqdm(range(len(structures))):\n",
    "        pi_bond_.append(pi_bond[structures.loc[i, 'atom']][str(structures.loc[i, 'n_bonds'])])\n",
    "\n",
    "    structures['pi_bonds'] = pi_bond_\n",
    "\n",
    "    return structures\n",
    "\n",
    "\n",
    "def electronegativity(atom_name, structures):\n",
    "    \"\"\"\n",
    "    :param: atom_name - list or np.ndarray consisting of name of atoms\n",
    "    :param: structures - structures data\n",
    "\n",
    "    Goal: Assign an electrinegativity for each atom\n",
    "\n",
    "    Return: structures with electrineativity column added\n",
    "    \"\"\"\n",
    "\n",
    "    electronegativity = {'H':2.2, 'C':2.55, 'N':3.04, 'O':3.44, 'F':3.98}\n",
    "    en_ = [electronegativity[x] for x in tqdm(atom_name)]\n",
    "\n",
    "    structures['EN'] = en_\n",
    "\n",
    "    return structures\n",
    "\n",
    "\n",
    "def radius(atom_name, structures):\n",
    "    \"\"\"\n",
    "    :param: atom_name - list or np.ndarray consisting of name of atoms\n",
    "    :param: structures - structures data\n",
    "\n",
    "    Goal: Assign an radius for each atom\n",
    "\n",
    "    Return: structures with radius column added\n",
    "    \"\"\"\n",
    "\n",
    "    atomic_radius = {'H':0.38, 'C':0.77, 'N':0.75, 'O':0.73, 'F':0.71} # Without fudge factor\n",
    "\n",
    "    fudge_factor = 0.05\n",
    "    atomic_radius = {k:v + fudge_factor for k,v in atomic_radius.items()}\n",
    "    rd_ = [atomic_radius[x] for x in atom_name]\n",
    "\n",
    "    structures['RD'] = rd_\n",
    "\n",
    "    return structures\n",
    "\n",
    "\n",
    "def map_atom_info(df_1,df_2, atom_idx):\n",
    "    \"\"\"\n",
    "    :param: df_1 - train data\n",
    "    :param: df_2 - structure data\n",
    "    :param: atom_ind - atom index in coupling\n",
    "\n",
    "    Goal: Merge two dataframe for further using\n",
    "\n",
    "    Return: A new dataframe after merged\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.merge(df_1, df_2, how = 'left',\n",
    "                  left_on  = ['molecule_name', f'atom_index_{atom_idx}'],\n",
    "                  right_on = ['molecule_name',  'atom_index'])\n",
    "    df = df.drop('atom_index', axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_closest(df_train):\n",
    "    df_temp=df_train.loc[:,[\"molecule_name\",\"atom_index_0\",\"atom_index_1\",\"distance\",\"x_0\",\"y_0\",\"z_0\",\"x_1\",\"y_1\",\"z_1\"]].copy()\n",
    "    df_temp_=df_temp.copy()\n",
    "    df_temp_= df_temp_.rename(columns={'atom_index_0': 'atom_index_1',\n",
    "                                       'atom_index_1': 'atom_index_0',\n",
    "                                       'x_0': 'x_1',\n",
    "                                       'y_0': 'y_1',\n",
    "                                       'z_0': 'z_1',\n",
    "                                       'x_1': 'x_0',\n",
    "                                       'y_1': 'y_0',\n",
    "                                       'z_1': 'z_0'})\n",
    "\n",
    "    df_temp=pd.concat(objs=[df_temp,df_temp_],axis=0)\n",
    "\n",
    "    df_temp[\"min_distance\"]=df_temp.groupby(['molecule_name', 'atom_index_0'])['distance'].transform('min')\n",
    "    df_temp= df_temp[df_temp[\"min_distance\"]==df_temp[\"distance\"]]\n",
    "\n",
    "    df_temp=df_temp.drop(['x_0','y_0','z_0','min_distance'], axis=1)\n",
    "    df_temp= df_temp.rename(columns={'atom_index_0': 'atom_index',\n",
    "                                     'atom_index_1': 'atom_index_closest',\n",
    "                                     'distance': 'distance_closest',\n",
    "                                     'x_1': 'x_closest',\n",
    "                                     'y_1': 'y_closest',\n",
    "                                     'z_1': 'z_closest'})\n",
    "\n",
    "    for atom_idx in [0,1]:\n",
    "        df_train = map_atom_info(df_train,df_temp, atom_idx)\n",
    "        df_train = df_train.rename(columns={'atom_index_closest': f'atom_index_closest_{atom_idx}',\n",
    "                                            'distance_closest': f'distance_closest_{atom_idx}',\n",
    "                                            'x_closest': f'x_closest_{atom_idx}',\n",
    "                                            'y_closest': f'y_closest_{atom_idx}',\n",
    "                                            'z_closest': f'z_closest_{atom_idx}'})\n",
    "    return df_train\n",
    "\n",
    "\n",
    "def add_cos_features(df):\n",
    "    \"\"\"\n",
    "    :param: df - dataframe containing necessary data for calculating the cosine value\n",
    "\n",
    "    Goal: Calculating cosine value\n",
    "\n",
    "    Return: dataframe with cosine data added\n",
    "    \"\"\"\n",
    "\n",
    "    # The modulus of the \n",
    "    df[\"distance_0\"]=((df['x_0']-df['x_closest_0'])**2+(df['y_0']-df['y_closest_0'])**2+(df['z_0']-df['z_closest_0'])**2)**(1/2)\n",
    "    df[\"distance_1\"]=((df['x_1']-df['x_closest_1'])**2+(df['y_1']-df['y_closest_1'])**2+(df['z_1']-df['z_closest_1'])**2)**(1/2)\n",
    "    \n",
    "    # Unit vector along each direction\n",
    "    df[\"vec_0_x\"]=(df['x_0']-df['x_closest_0'])/df[\"distance_0\"]\n",
    "    df[\"vec_0_y\"]=(df['y_0']-df['y_closest_0'])/df[\"distance_0\"]\n",
    "    df[\"vec_0_z\"]=(df['z_0']-df['z_closest_0'])/df[\"distance_0\"]\n",
    "    df[\"vec_1_x\"]=(df['x_1']-df['x_closest_1'])/df[\"distance_1\"]\n",
    "    df[\"vec_1_y\"]=(df['y_1']-df['y_closest_1'])/df[\"distance_1\"]\n",
    "    df[\"vec_1_z\"]=(df['z_1']-df['z_closest_1'])/df[\"distance_1\"]\n",
    "    \n",
    "    # Ratio between the difference along each direction to the distance\n",
    "    df[\"vec_x\"]=(df['x_1']-df['x_0'])/df[\"distance\"]\n",
    "    df[\"vec_y\"]=(df['y_1']-df['y_0'])/df[\"distance\"]\n",
    "    df[\"vec_z\"]=(df['z_1']-df['z_0'])/df[\"distance\"]\n",
    "\n",
    "    # Cosine of each component\n",
    "    df[\"cos_0_1\"]=df[\"vec_0_x\"]*df[\"vec_1_x\"]+df[\"vec_0_y\"]*df[\"vec_1_y\"]+df[\"vec_0_z\"]*df[\"vec_1_z\"]\n",
    "    df[\"cos_0\"]=df[\"vec_0_x\"]*df[\"vec_x\"]+df[\"vec_0_y\"]*df[\"vec_y\"]+df[\"vec_0_z\"]*df[\"vec_z\"]\n",
    "    df[\"cos_1\"]=df[\"vec_1_x\"]*df[\"vec_x\"]+df[\"vec_1_y\"]*df[\"vec_y\"]+df[\"vec_1_z\"]*df[\"vec_z\"]\n",
    "\n",
    "    df=df.drop(['vec_0_x','vec_0_y','vec_0_z','vec_1_x','vec_1_y','vec_1_z','vec_x','vec_y','vec_z'], axis=1)\n",
    "\n",
    "    # Angle for each component\n",
    "    df[\"Angle\"] = df[\"cos_0_1\"].apply(lambda x: np.arccos(x)) * 180 / np.pi\n",
    "    df[\"cos_0\"] = df[\"cos_0\"].apply(lambda x: np.arccos(x)) * 180 / np.pi\n",
    "    df[\"cos_1\"] = df[\"cos_1\"].apply(lambda x: np.arccos(x)) * 180 / np.pi\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# File paths\n",
    "train_path = r'\\\\icnas4.cc.ic.ac.uk\\fl4718\\Desktop\\Machine learning\\Data\\train.csv'\n",
    "structures_path = r'\\\\icnas4.cc.ic.ac.uk\\fl4718\\Desktop\\Machine learning\\Data\\structures.csv'\n",
    "test_path = r'\\\\icnas4.cc.ic.ac.uk\\fl4718\\Desktop\\Machine learning\\Data\\test.csv'\n",
    "\n",
    "# read data from local address\n",
    "train_df_full = pd.read_csv(train_path, index_col=0)\n",
    "structures_df_full = pd.read_csv(structures_path, dtype={'atom_index': np.int8})\n",
    "test_df_full = pd.read_csv(test_path)\n",
    "\n",
    "# Add distance feature to the test and trin data\n",
    "train_df = distance(train_df_full, structures_df_full)\n",
    "test_df = distance(test_df_full, structures_df_full)\n",
    "\n",
    "# ndarray with names of each atom in the structures csv\n",
    "atom = structures_df_full['atom'].values\n",
    "\n",
    "# Add electronegativity and radius colmun to the structures csv\n",
    "structures = electronegativity(atom, structures_df_full)\n",
    "structures = radius(atom, structures)\n",
    "\n",
    "# Add number of bonds and connecting atoms columns\n",
    "structures = n_bonds(structures)\n",
    "\n",
    "# Add hybridization column\n",
    "structures = hybridization(structures)\n",
    "\n",
    "# Add pi_bonds column\n",
    "structures = pi_bonds(structures)\n",
    "\n",
    "# Merge structures data and train data\n",
    "struc_train = struc1_merge(train_df, structures, 0)\n",
    "struc_train = struc1_merge(struc_train, structures, 1)\n",
    "\n",
    "struc_train = struc_train.drop(['atom_index_x', 'atom_x', 'x_x', 'y_x', 'z_x',\n",
    "                                'atom_index_y', 'atom_y','x_y', 'y_y', 'z_y'], axis=1)\n",
    "\n",
    "# Add bond angle column\n",
    "struc_train = create_closest(struc_train)\n",
    "struc_train = add_cos_features(struc_train)\n",
    "\n",
    "# The list of type for further training\n",
    "type_list = list(struc_train['type'].unique())\n",
    "\n",
    "# Drop the target column for training\n",
    "y = struc_train['scalar_coupling_constant']\n",
    "struc_train = struc_train.drop(['scalar_coupling_constant'], axis=1)\n",
    "\n",
    "# Select features for training\n",
    "X = struc_train[['molecule_name',\n",
    "                           'type',\n",
    "                           'distance',\n",
    "                           'EN_0',\n",
    "                           'RD_0',\n",
    "                           'hybri_0',\n",
    "                           'pi_bonds_0',\n",
    "                           'EN_1',\n",
    "                           'RD_1',\n",
    "                           'hybri_1',\n",
    "                           'pi_bonds_1',\n",
    "                           'cos_0_1']]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
